{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "776de359-0766-40b3-bf8d-5b4fd59242be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from transformers import ViTForImageClassification, ViTConfig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85fe58da-891d-4886-917c-89678bb311a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Append .tif extension to the image name\n",
    "        img_name = os.path.join(self.img_dir, self.data.iloc[idx]['id'] + '.tif')\n",
    "        image = Image.open(img_name)\n",
    "        label = self.data.iloc[idx]['label']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f492e7-3a97-40e9-97b7-f1cd2b2c09e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.image_ids = self.data['id'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Append .tif extension to the image name\n",
    "        img_name = os.path.join(self.img_dir, self.image_ids[idx] + '.tif')\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.image_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bf2149a-acf5-4dd6-8f11-2d7e3cebd4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc='Training',mininterval=2.0):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ca1dc18-075a-4f02-97e1-9e7fa2fbd427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc='Evaluating',mininterval=2.0):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "\n",
    "    val_loss = running_loss / len(val_loader)\n",
    "    val_acc = 100. * correct / total\n",
    "    return val_loss, val_acc, all_preds, all_labels, all_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e30ad69-e1ca-477e-ba64-73f63ed3050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(train_losses, train_accs, val_losses, val_accs):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Train Acc')\n",
    "    plt.plot(val_accs, label='Val Acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b83105b2-68b3-4be4-9fcb-f664a43fac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    classes = ['Class 0', 'Class 1']\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "089d5e8a-28e9-4cc9-aeb9-2a57cc86c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, roc_auc):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79f66972-87e0-4264-a34b-84ce0883ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict():\n",
    "    # Device configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Data transforms - must match training transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((96, 96)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load test dataset\n",
    "    test_dataset = TestDataset(\n",
    "        csv_file='sample_submission.csv',\n",
    "        img_dir='test',\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Initialize and load trained model\n",
    "    config = ViTConfig(\n",
    "        image_size=96,\n",
    "        patch_size=8,\n",
    "        num_channels=3,\n",
    "        num_classes=2,\n",
    "        num_hidden_layers=6,\n",
    "        hidden_size=384,\n",
    "        num_attention_heads=6,\n",
    "        intermediate_size=1536\n",
    "    )\n",
    "    model = ViTForImageClassification(config).to(device)\n",
    "    \n",
    "    # Load the best model weights\n",
    "    model.load_state_dict(torch.load('best_model_vit3.pth'))\n",
    "    model.eval()\n",
    "    \n",
    "    # Dictionary to store predictions\n",
    "    predictions = {}\n",
    "    \n",
    "    # Predict\n",
    "    print(\"Making predictions...\")\n",
    "    with torch.no_grad():\n",
    "        for images, image_ids in tqdm(test_loader,mininterval=2.0):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images).logits\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            # Store predictions\n",
    "            for idx, image_id in enumerate(image_ids):\n",
    "                predictions[image_id] = predicted[idx].item()\n",
    "    \n",
    "    # Load submission file and update predictions\n",
    "    submission_df = pd.read_csv('sample_submission.csv')\n",
    "    submission_df['label'] = submission_df['id'].map(predictions)\n",
    "    \n",
    "    # Save predictions\n",
    "    submission_df.to_csv('sample_submission_vit_small_03.csv', index=False)\n",
    "    print(\"Predictions saved to sample_submission_vit_small_03.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e54ebff-c604-4112-86a7-2237f173d880",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.chdir('prueba_us')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6bea046-ea08-4dbe-8d10-7864a5e74718",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 2e-4\n",
    "VAL_SPLIT = 0.1\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((96, 96)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = MedicalImageDataset(\n",
    "    csv_file='train.csv',\n",
    "    img_dir='train',\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93948f55-9b10-4857-8b84-5b04a711531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "val_size = int(VAL_SPLIT * len(dataset))\n",
    "train_size = len(dataset) - val_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "084738cd-d3b9-443d-a804-2f9b4ce0775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "config = ViTConfig(\n",
    "    image_size=96,\n",
    "    patch_size=8,\n",
    "    num_channels=3,\n",
    "    num_classes=2,\n",
    "    num_hidden_layers=6,\n",
    "    hidden_size=384,\n",
    "    num_attention_heads=6,\n",
    "    intermediate_size=1536,\n",
    "    hidden_dropout_prob=0.3,  # Agregar dropout en las capas ocultas\n",
    "    attention_probs_dropout_prob=0.3  # Agregar dropout en la atención\n",
    ")\n",
    "model = ViTForImageClassification(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708d999e-9f65-4f86-968b-ec948dbffb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [30:05<00:00,  3.08it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [03:52<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3866 Train Acc: 82.69%\n",
      "Val Loss: 0.5805 Val Acc: 75.31%\n",
      "\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [30:30<00:00,  3.04it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [03:11<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3439 Train Acc: 85.05%\n",
      "Val Loss: 0.3763 Val Acc: 83.22%\n",
      "\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [26:56<00:00,  3.45it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:14<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3224 Train Acc: 86.05%\n",
      "Val Loss: 0.3297 Val Acc: 85.62%\n",
      "\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [12:32<00:00,  7.40it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:16<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3060 Train Acc: 86.91%\n",
      "Val Loss: 0.3690 Val Acc: 83.53%\n",
      "\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [12:34<00:00,  7.38it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:17<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2908 Train Acc: 87.63%\n",
      "Val Loss: 0.3481 Val Acc: 86.08%\n",
      "\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [12:46<00:00,  7.27it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:16<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2767 Train Acc: 88.41%\n",
      "Val Loss: 0.3158 Val Acc: 86.90%\n",
      "\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [12:39<00:00,  7.33it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:18<00:00,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2639 Train Acc: 88.98%\n",
      "Val Loss: 0.2531 Val Acc: 89.59%\n",
      "\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [12:23<00:00,  7.50it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:03<00:00,  9.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2530 Train Acc: 89.52%\n",
      "Val Loss: 0.2606 Val Acc: 89.31%\n",
      "\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:16<00:00,  8.24it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:04<00:00,  9.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2426 Train Acc: 90.04%\n",
      "Val Loss: 0.2535 Val Acc: 89.80%\n",
      "\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:24<00:00,  8.13it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:05<00:00,  9.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2317 Train Acc: 90.53%\n",
      "Val Loss: 0.2404 Val Acc: 90.38%\n",
      "\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:19<00:00,  8.20it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:06<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2202 Train Acc: 91.07%\n",
      "Val Loss: 0.3768 Val Acc: 84.28%\n",
      "\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:27<00:00,  8.11it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:06<00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2113 Train Acc: 91.46%\n",
      "Val Loss: 0.2428 Val Acc: 90.16%\n",
      "\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:22<00:00,  8.16it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:04<00:00,  9.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2016 Train Acc: 91.96%\n",
      "Val Loss: 0.2119 Val Acc: 91.42%\n",
      "\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:20<00:00,  8.18it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:06<00:00,  9.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1924 Train Acc: 92.31%\n",
      "Val Loss: 0.2152 Val Acc: 91.39%\n",
      "\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:25<00:00,  8.12it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:06<00:00,  9.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1872 Train Acc: 92.62%\n",
      "Val Loss: 0.2153 Val Acc: 91.30%\n",
      "\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:18<00:00,  8.21it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:05<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1774 Train Acc: 93.02%\n",
      "Val Loss: 0.2671 Val Acc: 89.78%\n",
      "\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:24<00:00,  8.14it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:06<00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1703 Train Acc: 93.36%\n",
      "Val Loss: 0.2386 Val Acc: 90.95%\n",
      "\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:19<00:00,  8.19it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:05<00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1668 Train Acc: 93.46%\n",
      "Val Loss: 0.2921 Val Acc: 88.97%\n",
      "\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:26<00:00,  8.12it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:06<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1582 Train Acc: 93.84%\n",
      "Val Loss: 0.2362 Val Acc: 90.95%\n",
      "\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:25<00:00,  8.12it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:06<00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1527 Train Acc: 94.08%\n",
      "Val Loss: 0.1998 Val Acc: 92.18%\n",
      "\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:27<00:00,  8.11it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:05<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1475 Train Acc: 94.31%\n",
      "Val Loss: 0.2266 Val Acc: 91.05%\n",
      "\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▌    | 3132/5570 [06:25<05:01,  8.09it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Training: 100%|██████████| 5570/5570 [11:25<00:00,  8.13it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:03<00:00,  9.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0896 Train Acc: 96.62%\n",
      "Val Loss: 0.2162 Val Acc: 92.47%\n",
      "\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:31<00:00,  8.05it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:06<00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0866 Train Acc: 96.71%\n",
      "Val Loss: 0.1911 Val Acc: 93.50%\n",
      "\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:40<00:00,  7.95it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:06<00:00,  9.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0841 Train Acc: 96.83%\n",
      "Val Loss: 0.2265 Val Acc: 93.02%\n",
      "\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [13:37<00:00,  6.81it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [03:08<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0819 Train Acc: 96.93%\n",
      "Val Loss: 0.1989 Val Acc: 93.39%\n",
      "\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [15:50<00:00,  5.86it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:10<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0804 Train Acc: 96.97%\n",
      "Val Loss: 0.2105 Val Acc: 93.39%\n",
      "\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:46<00:00,  7.88it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:10<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0782 Train Acc: 97.09%\n",
      "Val Loss: 0.1952 Val Acc: 93.33%\n",
      "\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:43<00:00,  7.92it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:08<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0759 Train Acc: 97.14%\n",
      "Val Loss: 0.2344 Val Acc: 92.48%\n",
      "\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [19:45<00:00,  4.70it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [02:58<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0741 Train Acc: 97.25%\n",
      "Val Loss: 0.2307 Val Acc: 93.06%\n",
      "\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [22:34<00:00,  4.11it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:11<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0717 Train Acc: 97.33%\n",
      "Val Loss: 0.2031 Val Acc: 93.57%\n",
      "\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:15<00:00,  8.25it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:05<00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0701 Train Acc: 97.39%\n",
      "Val Loss: 0.2156 Val Acc: 93.26%\n",
      "\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:06<00:00,  8.36it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:04<00:00,  9.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0689 Train Acc: 97.42%\n",
      "Val Loss: 0.2644 Val Acc: 92.28%\n",
      "\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:04<00:00,  8.39it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:01<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0659 Train Acc: 97.54%\n",
      "Val Loss: 0.2228 Val Acc: 93.40%\n",
      "\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:03<00:00,  8.39it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:03<00:00,  9.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0662 Train Acc: 97.50%\n",
      "Val Loss: 0.2820 Val Acc: 91.48%\n",
      "\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5570/5570 [11:05<00:00,  8.37it/s]\n",
      "Evaluating: 100%|██████████| 619/619 [01:04<00:00,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0641 Train Acc: 97.61%\n",
      "Val Loss: 0.2274 Val Acc: 93.67%\n",
      "\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 408/5570 [00:49<10:26,  8.24it/s]"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Training tracking\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "best_val_acc = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f'\\nEpoch {epoch+1}/{NUM_EPOCHS}')\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, val_preds, val_labels, val_probs = evaluate(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    print(f'Train Loss: {train_loss:.4f} Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Val Loss: {val_loss:.4f} Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_model_vit3.pth')\n",
    "\n",
    "# Plot training curves\n",
    "plot_metrics(train_losses, train_accs, val_losses, val_accs)\n",
    "\n",
    "# Calculate final metrics\n",
    "precision = precision_score(val_labels, val_preds)\n",
    "recall = recall_score(val_labels, val_preds)\n",
    "f1 = f1_score(val_labels, val_preds)\n",
    "cm = confusion_matrix(val_labels, val_preds)\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(val_labels, val_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Print final metrics\n",
    "print('\\nFinal Metrics:')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f'ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "# Plot confusion matrix and ROC curve\n",
    "plot_confusion_matrix(cm)\n",
    "plot_roc_curve(fpr, tpr, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4273a822-ccf3-4b1f-a1bc-c39b3af1fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
